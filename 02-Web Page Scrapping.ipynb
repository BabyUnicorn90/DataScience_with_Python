{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "req = urlopen(\"https://news.daum.net/\")\n",
    "#print(\"응답 코드: \", req.getcode())    # >>200: 성공! \n",
    "\n",
    "if req.getcode() == 200: \n",
    "    #코드받아오기\n",
    "    html = req.read()\n",
    "    html = html.decode(\"utf-8\")\n",
    "    print(\"SUCCESS\")\n",
    "else: \n",
    "    print(\"HTTP=ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서제목:  홈 | 다음뉴스\n"
     ]
    }
   ],
   "source": [
    "# text -> html dom으로 변경\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "#print(soup.prettify())\n",
    "\n",
    "#문서정보 확인하기\n",
    "print(\"문서제목: \", soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'select'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d8987afc4642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(articles)  #div#mArticle 자손인 a.link_txt 검색하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a.link_txt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#클래스가 link_txt인 a태그 검색하라!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2173\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 2174\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'select'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "# 주요기사 div 검색하기: select or find\n",
    "articles = soup.select(\"#mArticle\")   #id가 mArticle인 div 검색\n",
    "#print(articles)  #div#mArticle 자손인 a.link_txt 검색하기\n",
    "\n",
    "links = articles.select(\"a.link_txt\") #클래스가 link_txt인 a태그 검색하라!\n",
    "print(links)\n",
    "\n",
    "#기사 목록을 { \"link\": ....url주소... \"title\" .....}의 리스트 만들기\n",
    "news_list = []\n",
    "\n",
    "for link in links:\n",
    "    news = {\n",
    "        \"link\": link['href'],   #속성에 접근\n",
    "        \"title\": link.text.strip()\n",
    "    }\n",
    "    news_list.append(news)\n",
    "\n",
    "#print(news_list)\n",
    "\n",
    "#print(\"다음뉴스 주요기사: \")\n",
    "#for news in news_list:\n",
    "    #print(\"{} - {}\".format(news.get('title'), news.get('link')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<<<< 연습문제 >>>>>\n",
    "# 다음 뉴스 상단 div#cSub인 뉴스 수집하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://movie.naver.com/movie/running/current.nhn\n",
    "#영화 순위 목록 수집하기 \n",
    "\n",
    "req = urlopen(\"https://movie.naver.com/movie/running/current.nhn\")\n",
    "html_str = req.read().decode('utf-8')\n",
    "#print(html_str[:256])     #html text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOM 변환\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "#print(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ul.lst_detail_t1\n",
    "current_movies = soup.select(\"ul.lst_detail_t1 > li\")\n",
    "# class = lst_detail_t1인 ul의 자식인 li 태그들 \n",
    "# print(current_movies)\n",
    "\n",
    "#영화의 세부정보 검색하기\n",
    "movie_list = []\n",
    "\n",
    "for movie in current_movies:\n",
    "    titles = movie.select(\"dl.lst_dsc > .tit > a\")[0]\n",
    "    \n",
    "    info = {\"title\": titles.text.strip(), \"link\": titles['href']}\n",
    "    movie_list.append(info)\n",
    "\n",
    "#print(movie_list)\n",
    "\n",
    "print(\"네이버 영화 순위\")\n",
    "\n",
    "for rank, info in enumerate(movie_list):\n",
    "    print(\"{}위 - {} : {}\".format(rank+1, info['title'], info['link']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 이미지 다운로드: urlretrieve\n",
    "# ul.lst_detail_t1 > li  --> img태그 확인\n",
    "# img태그의 속성: src, alt(대체텍스트) 확인\n",
    "# 저장 디렉터리 확인: \n",
    "import os\n",
    "import re    #정규표현식 모듈\n",
    "from urllib.request import  urlretrieve\n",
    "\n",
    "if not os.path.exists(\"d:/data-science/crawl\"):  #저장디렉터리가 없으면 \n",
    "    os.makedirs(\"d:/data-science/crawl\")  #생성하라 \n",
    "\n",
    "for movie in current_movies:\n",
    "    img_tag = movie.select(\"img\")[0]\n",
    "    #print(\"포스터: \", img_tag)\n",
    "    #print(\"src: \", img_tag['src'])\n",
    "    #print(\"img: \", img_tag['alt'])\n",
    "    #but 위 방법으로 그대로 저장하면 파일명으로 사용할 수 없는 문자가 있으므로 \n",
    "    #정규표현식 모듈 import\n",
    "    title = img_tag['alt']\n",
    "    title = re.sub(r\"[\\/:*?<>|.]\", \"-\", title.strip())\n",
    "    #print(\"정제된 제목: \", title)\n",
    "    \n",
    "    src = img_tag['src']  #이미지 주소\n",
    "    target = \"d:/data-science/crawl/{}.jpg\".format(title)\n",
    "    \n",
    "    #이미지 다운로드: urlretrieve모듈\n",
    "    urlretrieve(src, target)\n",
    "    print(\".\", end=\"\")\n",
    "else:\n",
    "    print(\"Download Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<<<< 연습문제 >>>>>\n",
    "# 네이버 개봉예정 영화 정보 수집하기 \n",
    "# https://movie.naver.com/movie/running/premovie.nhn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
